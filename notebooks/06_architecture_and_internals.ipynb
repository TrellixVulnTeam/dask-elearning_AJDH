{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca839aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b35459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ccfc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f3704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd47af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07645591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b25a8d10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Dask Distributed Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128c27b",
   "metadata": {},
   "source": [
    "There are a few different Dask schedulers, but when starting out on your Dask journey you only need to know about the most powerful and feature-complete one: the **distributed scheduler**. This scheduler offers more features and diagnostics. You can think of the distributed scheduler as an advanced scheduler that also does the basic stuff really well.\n",
    "\n",
    "The distributed scheduler can be used in a cluster as well as locally. Deploying a remote Dask cluster involves additional setup that you can read more about on the Dask [setup documentation](https://docs.dask.org/en/latest/setup.html). Alternatively, you can use [Coiled](https://docs.coiled.io/user_guide/index.html#what-is-coiled) which provides a cluster-as-a-service functionality to provision hosted Dask clusters on demand, and you can try it for free.  \n",
    "\n",
    "For now, we will set up the scheduler locally. To set up the distributed scheduler locally we need to create a `Client` object, which will let you interact with the \"cluster\" (local threads or processes on your machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "\n",
    "client = Client(n_workers=8) #shorthand for creating a 'local cluster' of all your machine's cores\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c1e02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Dask Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e309bc",
   "metadata": {},
   "source": [
    "When we create a distributed scheduler Client, it registers itself as the default Dask scheduler. From now on, all `.compute()` calls will start using the distributed scheduler unless otherwise is specified.\n",
    "\n",
    "The distributed scheduler has many features that you can learn more about in the Dask distributed documentation but a nice feature to explore is diagnostic the Dashboard. We will be taking a look at the dashboard as we perform computations but for a brief overview of the main components of the dashboard you can check the Dask documentation on diagnosing performance.\n",
    "\n",
    "If you click on the link of the dashboard on the cell above and run the computation we did before you will see now some action happening on the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.groupby(\"DayOfWeek\")[\"DepDelay\"].mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f87892",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfcfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae111ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1ea9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bd23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c357a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf85a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc1cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00881ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f44fe100",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352c066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accc007d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b79ea7",
   "metadata": {},
   "source": [
    "Let's look at the task graph for our Dask DataFrame to get a sense for where these partitions are coming from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5b036",
   "metadata": {},
   "source": [
    "Each partition in our Dask DataFrame is the result of calling Pandas' `read_csv` on an input CSV file in our dataset.\n",
    "\n",
    "We can view the start of the data with `df.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1bcb06",
   "metadata": {},
   "source": [
    "`.head()` triggers a computation to show the first 10 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb980f67",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dask/dask/main/docs/source/images/dask-overview.svg\" \n",
    "     width=\"100%\"\n",
    "     alt=\"Dask overview\\\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dask-dataframes]",
   "language": "python",
   "name": "conda-env-dask-dataframes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
